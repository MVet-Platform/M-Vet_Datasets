{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#imports\nimport os\nimport pandas as pd\nfrom glob import glob\nimport tensorflow as tf\nfrom tensorflow.keras import losses, optimizers, layers, Sequential\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get image data\nos.makedirs('body_score_dataset', exist_ok=True)\n!git clone -b body_scores_prediction_dataset https://github.com/MVet-Platform/M-Vet_Hackathon24.git ./body_score_dataset ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load label data\ndf_train_data = pd.read_csv('/kaggle/working/body_score_dataset/train_data.csv')\ndf_train_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_data['bodyScore'].hist()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get file path for image files\ndf_train_data['filepath'] = df_train_data.apply(lambda row: glob(f'body_score_dataset/**/{row.filename}')[0], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create array of body scores and file paths\nbody_scores = df_train_data.bodyScore.values\nfile_paths = df_train_data.filepath.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load image and body_score\n#apply preprocessing to image\n#return image and body_score\ndef load_and_preprocess_image(file_path, body_score=None):\n    image = tf.io.read_file(file_path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize(image, [224, 224]) \n    image = tf.cast(image, tf.float32) / 255.0 \n    if body_score is not None:\n        return image, body_score\n    else:\n        return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a TensorFlow dataset\ndataset = tf.data.Dataset.from_tensor_slices((file_paths, body_scores))\ndataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#view contents of dataset\nfor item in dataset.take(1):\n    plt.title(f'Body Score: {item[1].numpy()}')\n    plt.imshow(item[0].numpy())\n    plt.axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#shuffle and batch data\ndataset = dataset.shuffle(buffer_size=2000)\ndataset = dataset.batch(batch_size=32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#split data into train and val sets\ndataset_length = 0\nfor _ in dataset:\n    dataset_length+=1\nprint(dataset_length)\ntrain_size = int(dataset_length*0.7)\ntrain_dataset = dataset.take(train_size)\nval_dataset = dataset.skip(train_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create model\nbase_model = tf.keras.applications.ResNet50(\n    include_top=False,\n    weights='imagenet',\n    pooling='avg',\n)\n\nmodel = Sequential()\nmodel.add(base_model)\n# model.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n# model.add(layers.MaxPool2D())\n# model.add(layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'))\n# model.add(layers.MaxPool2D())\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(units=1024, activation='relu'))\nmodel.add(layers.Dense(units=1, activation='relu'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#compile model\nmodel.compile(loss=losses.mae, optimizer=optimizers.RMSprop())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train model\nmodel.fit(train_dataset, validation_data=val_dataset, epochs=20, batch_size=32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load submission file\ndf_submit = pd.read_csv('/kaggle/working/body_score_dataset/sample_submission.csv')\ndf_submit.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#prepare test dataset\ndf_submit['filepath'] = df_submit.apply(lambda row: glob(f'body_score_dataset/**/{row.filename}')[0], axis=1)\ndf_submit_file_paths = df_submit.filepath.values\ntest_dataset = tf.data.Dataset.from_tensor_slices((df_submit_file_paths))\ntest_dataset = test_dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\ntest_dataset = test_dataset.batch(32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#make predictions\npredictions = model.predict(test_dataset)\npredictions_flattened = predictions.flatten()\ndf_submit['bodyScore'] = [5.0 if i>5 else i for i in predictions_flattened]\ndf_submit[['filename', 'bodyScore']].to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}